{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "397e1d8a-249e-417e-b71b-0582fb74cd64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[3]: True"
     ]
    }
   ],
   "source": [
    "dbutils.fs.rm(\"/FileStore/tables/\", recurse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af951c45-4072-4413-886d-3b905df7a03a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[10]: [FileInfo(path='dbfs:/FileStore/tables/s1.csv', name='s1.csv', size=592, modificationTime=1745242183000),\n",
      " FileInfo(path='dbfs:/FileStore/tables/s2.csv', name='s2.csv', size=247, modificationTime=1745244457000)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls(\"/FileStore/tables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6b4b656-73de-4972-8375-98f1798e0124",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum as _sum, count, window, to_timestamp\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, TimestampType\n",
    "\n",
    "# ✅ Define schema matching your dataset (Date stays StringType initially)\n",
    "schema = StructType([\n",
    "    StructField(\"Transaction ID\", IntegerType(), True),\n",
    "    StructField(\"Date\", StringType(), True),  # Parse later\n",
    "    StructField(\"Customer ID\", StringType(), True),\n",
    "    StructField(\"Gender\", StringType(), True),\n",
    "    StructField(\"Age\", IntegerType(), True),\n",
    "    StructField(\"Product Category\", StringType(), True),\n",
    "    StructField(\"Quantity\", IntegerType(), True),\n",
    "    StructField(\"Price per Unit\", DoubleType(), True),\n",
    "    StructField(\"Total Amount\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "# ✅ Read stream from DBFS\n",
    "df = spark.readStream \\\n",
    "    .option(\"header\", True) \\\n",
    "    .schema(schema) \\\n",
    "    .csv(\"/FileStore/tables\")\n",
    "\n",
    "# ✅ Convert Date column to TimestampType using proper format\n",
    "df = df.withColumn(\"Date\", to_timestamp(\"Date\", \"dd-MM-yyyy\"))\n",
    "\n",
    "# ✅ 10-minute windowed revenue per product category\n",
    "revenue_by_category = df.groupBy(\n",
    "    window(col(\"Date\"), \"10 minutes\"),\n",
    "    col(\"Product Category\")\n",
    ").agg(\n",
    "    _sum(\"Total Amount\").alias(\"total_revenue\")\n",
    ")\n",
    "\n",
    "# ✅ 10-minute windowed transaction count per gender\n",
    "transactions_by_gender = df.groupBy(\n",
    "    window(col(\"Date\"), \"10 minutes\"),\n",
    "    col(\"Gender\")\n",
    ").agg(\n",
    "    count(\"Transaction ID\").alias(\"total_transactions\")\n",
    ")\n",
    "\n",
    "# ✅ Top categories overall (not windowed)\n",
    "top_categories = df.groupBy(\"Product Category\") \\\n",
    "    .agg(count(\"Transaction ID\").alias(\"transaction_count\")) \\\n",
    "    .orderBy(col(\"transaction_count\").desc())\n",
    "\n",
    "# ✅ Write to memory tables for SQL queries\n",
    "revenue_query = revenue_by_category.writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .queryName(\"revenue_category_table\") \\\n",
    "    .start()\n",
    "\n",
    "gender_query = transactions_by_gender.writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .queryName(\"gender_transactions_table\") \\\n",
    "    .start()\n",
    "\n",
    "top_query = top_categories.writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .queryName(\"top_categories_table\") \\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59d894a4-f6ba-444c-95b1-8d4a0bb0b1dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+----------------+-------------+\n",
      "|window_start       |window_end         |Product Category|total_revenue|\n",
      "+-------------------+-------------------+----------------+-------------+\n",
      "|2023-08-05 00:00:00|2023-08-05 00:10:00|Electronics     |1500.0       |\n",
      "|2023-02-27 00:00:00|2023-02-27 00:10:00|Clothing        |1000.0       |\n",
      "|2023-12-13 00:00:00|2023-12-13 00:10:00|Electronics     |600.0        |\n",
      "|2023-05-21 00:00:00|2023-05-21 00:10:00|Clothing        |500.0        |\n",
      "|2023-10-07 00:00:00|2023-10-07 00:10:00|Clothing        |200.0        |\n",
      "|2023-11-24 00:00:00|2023-11-24 00:10:00|Beauty          |150.0        |\n",
      "|2023-02-22 00:00:00|2023-02-22 00:10:00|Electronics     |100.0        |\n",
      "|2023-05-06 00:00:00|2023-05-06 00:10:00|Beauty          |100.0        |\n",
      "|2023-02-14 00:00:00|2023-02-14 00:10:00|Clothing        |100.0        |\n",
      "|2023-10-30 00:00:00|2023-10-30 00:10:00|Beauty          |75.0         |\n",
      "|2023-03-13 00:00:00|2023-03-13 00:10:00|Clothing        |50.0         |\n",
      "|2023-01-13 00:00:00|2023-01-13 00:10:00|Electronics     |30.0         |\n",
      "|2023-04-25 00:00:00|2023-04-25 00:10:00|Beauty          |30.0         |\n",
      "+-------------------+-------------------+----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Revenue by product category (10-minute windowed)\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        window.start AS window_start, \n",
    "        window.end AS window_end, \n",
    "        `Product Category`, \n",
    "        total_revenue \n",
    "    FROM revenue_category_table\n",
    "    ORDER BY total_revenue DESC\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a40a63a-cb65-4cc3-9d61-70e4fea585af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------+------------------+\n",
      "|window_start       |window_end         |Gender|total_transactions|\n",
      "+-------------------+-------------------+------+------------------+\n",
      "|2023-11-24 00:00:00|2023-11-24 00:10:00|Male  |1                 |\n",
      "|2023-02-27 00:00:00|2023-02-27 00:10:00|Female|1                 |\n",
      "|2023-04-25 00:00:00|2023-04-25 00:10:00|Female|1                 |\n",
      "|2023-01-13 00:00:00|2023-01-13 00:10:00|Male  |1                 |\n",
      "|2023-05-21 00:00:00|2023-05-21 00:10:00|Male  |1                 |\n",
      "|2023-08-05 00:00:00|2023-08-05 00:10:00|Male  |1                 |\n",
      "|2023-05-06 00:00:00|2023-05-06 00:10:00|Male  |1                 |\n",
      "|2023-02-22 00:00:00|2023-02-22 00:10:00|Male  |1                 |\n",
      "|2023-03-13 00:00:00|2023-03-13 00:10:00|Male  |1                 |\n",
      "|2023-10-30 00:00:00|2023-10-30 00:10:00|Male  |1                 |\n",
      "|2023-10-07 00:00:00|2023-10-07 00:10:00|Female|1                 |\n",
      "|2023-02-14 00:00:00|2023-02-14 00:10:00|Male  |1                 |\n",
      "|2023-12-13 00:00:00|2023-12-13 00:10:00|Male  |1                 |\n",
      "+-------------------+-------------------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Transactions by gender (10-minute windowed)\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        window.start AS window_start, \n",
    "        window.end AS window_end, \n",
    "        Gender, \n",
    "        total_transactions \n",
    "    FROM gender_transactions_table\n",
    "    ORDER BY total_transactions DESC\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b57b11e-82ca-4d32-a1f7-d70932c54934",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+\n",
      "|Product Category|transaction_count|\n",
      "+----------------+-----------------+\n",
      "|Clothing        |5                |\n",
      "|Electronics     |4                |\n",
      "|Beauty          |4                |\n",
      "+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Top overall product categories\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        `Product Category`, \n",
    "        transaction_count \n",
    "    FROM top_categories_table\n",
    "    ORDER BY transaction_count DESC\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdcafe4c-7cde-4ea4-b715-af7055e5cff1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+\n",
      "|Product Category|total_revenue|\n",
      "+----------------+-------------+\n",
      "|Electronics     |2230.0       |\n",
      "|Clothing        |1850.0       |\n",
      "|Beauty          |355.0        |\n",
      "+----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Total Revenue per Category (No Time Window)\n",
    "spark.sql(\"\"\"\n",
    "    SELECT `Product Category`, SUM(total_revenue) AS total_revenue\n",
    "    FROM revenue_category_table\n",
    "    GROUP BY `Product Category`\n",
    "    ORDER BY total_revenue DESC\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a03a7b4e-970c-4bf3-a36f-63267d9a23e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------+-----------------+-----------------+\n",
      "|window_start       |window_end         |Gender|transaction_count|revenue_generated|\n",
      "+-------------------+-------------------+------+-----------------+-----------------+\n",
      "|2023-08-05 00:00:00|2023-08-05 00:10:00|Male  |1                |1500.0           |\n",
      "|2023-02-27 00:00:00|2023-02-27 00:10:00|Female|1                |1000.0           |\n",
      "|2023-12-13 00:00:00|2023-12-13 00:10:00|Male  |1                |600.0            |\n",
      "|2023-05-21 00:00:00|2023-05-21 00:10:00|Male  |1                |500.0            |\n",
      "|2023-10-07 00:00:00|2023-10-07 00:10:00|Female|1                |200.0            |\n",
      "|2023-11-24 00:00:00|2023-11-24 00:10:00|Male  |1                |150.0            |\n",
      "|2023-02-14 00:00:00|2023-02-14 00:10:00|Male  |1                |100.0            |\n",
      "|2023-02-22 00:00:00|2023-02-22 00:10:00|Male  |1                |100.0            |\n",
      "|2023-05-06 00:00:00|2023-05-06 00:10:00|Male  |1                |100.0            |\n",
      "|2023-10-30 00:00:00|2023-10-30 00:10:00|Male  |1                |75.0             |\n",
      "|2023-03-13 00:00:00|2023-03-13 00:10:00|Male  |1                |50.0             |\n",
      "|2023-04-25 00:00:00|2023-04-25 00:10:00|Female|1                |30.0             |\n",
      "|2023-01-13 00:00:00|2023-01-13 00:10:00|Male  |1                |30.0             |\n",
      "+-------------------+-------------------+------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Gender-wise Total Revenue (Join Two Tables)\n",
    "spark.sql(\"\"\"\n",
    "    SELECT g.window.start AS window_start, \n",
    "           g.window.end AS window_end, \n",
    "           g.Gender, \n",
    "           COUNT(*) AS transaction_count, \n",
    "           SUM(r.total_revenue) AS revenue_generated\n",
    "    FROM gender_transactions_table g\n",
    "    LEFT JOIN revenue_category_table r\n",
    "    ON g.window = r.window\n",
    "    GROUP BY g.window.start, g.window.end, g.Gender\n",
    "    ORDER BY revenue_generated DESC\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85de0f22-4cee-4f8b-9c84-837f81829620",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------------+\n",
      "|Product Category|avg_transaction_value|\n",
      "+----------------+---------------------+\n",
      "|Electronics     |557.5                |\n",
      "|Clothing        |370.0                |\n",
      "|Beauty          |88.75                |\n",
      "+----------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Average Transaction Value per Category\n",
    "spark.sql(\"\"\"\n",
    "    SELECT `Product Category`, \n",
    "           SUM(total_revenue) / COUNT(*) AS avg_transaction_value\n",
    "    FROM revenue_category_table\n",
    "    GROUP BY `Product Category`\n",
    "    ORDER BY avg_transaction_value DESC\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f8b1f36-9b87-4208-b060-503e5408527e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|Gender|total_transactions|\n",
      "+------+------------------+\n",
      "|Male  |10                |\n",
      "|Female|3                 |\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gender Distribution of Transactions\n",
    "spark.sql(\"\"\"\n",
    "    SELECT Gender, SUM(total_transactions) AS total_transactions\n",
    "    FROM gender_transactions_table\n",
    "    GROUP BY Gender\n",
    "    ORDER BY total_transactions DESC\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d794fd86-93db-4a21-9115-354bff3fd321",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|Gender|total_transactions|\n",
      "+------+------------------+\n",
      "|Female|1                 |\n",
      "|Female|1                 |\n",
      "|Male  |1                 |\n",
      "|Male  |1                 |\n",
      "|Male  |1                 |\n",
      "|Female|1                 |\n",
      "|Male  |1                 |\n",
      "|Male  |1                 |\n",
      "|Male  |1                 |\n",
      "|Male  |1                 |\n",
      "|Male  |1                 |\n",
      "|Male  |1                 |\n",
      "|Male  |1                 |\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        Gender, \n",
    "        total_transactions \n",
    "    FROM gender_transactions_table\n",
    "    ORDER BY total_transactions DESC\n",
    "\"\"\").show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "stock_streaming_analysis1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
